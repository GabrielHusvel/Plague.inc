import streamlit as st
import time
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.firefox.options import Options
import streamlit as st

# Configura√ß√µes para o Selenium com Firefox
def setup_selenium():
    options = Options()
    options.headless = True 
    driver = webdriver.Firefox(options=options)
    return driver

# Fun√ß√£o para filtrar not√≠cias relacionadas √† dengue
def is_dengue_related(title, description):
    keywords = ['dengue', 'zika', 'chikungunya', 'mosquito']
    return any(keyword.lower() in title.lower() or keyword.lower() in description.lower() for keyword in keywords)

# Fun√ß√£o para organizar visualiza√ß√£o das not√≠cias
def show_news_column(news_data, column_title):
    with st.expander(column_title):
        for news in news_data:
            st.markdown(f"**[{news['title']}]({news['link']})**")
            st.write(news['date'])
            st.write(news['description'])


# Fun√ß√£o para fazer scraping da p√°gina
def scrape_dengue_info():
    driver = setup_selenium()
    url = 'https://www.gov.br/saude/pt-br/assuntos/saude-de-a-a-z/d/dengue'
    
    # Acessar a p√°gina
    driver.get(url)
    
    # Esperar que a p√°gina carregue completamente
    time.sleep(5)  # Ajuste esse tempo de espera conforme necess√°rio

    # Encontrar todos os par√°grafos com informa√ß√µes
    paragraphs = driver.find_elements(By.TAG_NAME, 'p')
    
    # Extrair o texto e armazenar em uma lista
    dengue_info = [p.text for p in paragraphs]
    
    # Fechar o driver
    driver.quit()
    
    # Retornar as informa√ß√µes coletadas
    return dengue_info

# Fun√ß√£o para fazer scraping da CNN (not√≠cias gerais)
def scrape_cnn_news():
    driver = setup_selenium()
    url = 'https://www.cnnbrasil.com.br/tudo-sobre/dengue/'
    driver.get(url)
    time.sleep(5)  # Ajuste esse tempo de espera conforme necess√°rio
    
    news_elements = driver.find_elements(By.CLASS_NAME, 'home__list__item')
    news_data = []
    for element in news_elements:
        title = element.find_element(By.TAG_NAME, 'h3').text
        link = element.find_element(By.TAG_NAME, 'a').get_attribute('href')
        date = element.find_element(By.CLASS_NAME, 'home__title__date').text
        description = element.find_element(By.TAG_NAME, 'a').get_attribute('title')
        if is_dengue_related(title, description):
            news_data.append({'title': title, 'link': link, 'date': date, 'description': description})
    
    driver.quit()
    return news_data

# Fun√ß√£o para fazer scraping das not√≠cias do estado e munic√≠pio (G1)
def scrape_g1_news(state, city=None):
    driver = setup_selenium()
    search_query = f"dengue {state}" + (f" {city}" if city else "")
    url = f"https://g1.globo.com/busca/?q={search_query}"
    driver.get(url)
    time.sleep(5)
    
    news_elements = driver.find_elements(By.CLASS_NAME, 'widget--info')
    news_data = []
    for element in news_elements:
        title = element.find_element(By.CLASS_NAME, 'widget--info__title').text
        link = element.find_element(By.TAG_NAME, 'a').get_attribute('href')
        description = element.find_element(By.CLASS_NAME, 'widget--info__description').text
        date = element.find_element(By.CLASS_NAME, 'widget--info__meta').text
        if is_dengue_related(title, description):
            news_data.append({'title': title, 'link': link, 'date': date, 'description': description})
    
    driver.quit()
    return news_data

# Fun√ß√£o para exibir as not√≠cias no Streamlit
def display_news(news, title):
    st.write(f"### {title}")
    for item in news:
        st.write(f"**{item['title']}**")
        st.write(f"[Link]({item['link']})")
        st.write(f"*Publicado em: {item['date']}*")
        st.write("---")


def exibir_noticias_informacoes():

    # Exibir as not√≠cias no Streamlit
    st.title("üîçNot√≠cias e informa√ß√µes sobre Dengueüîç")

    # Infoma√ß√£o
    if st.button("Informa√ß√µes sobre Dengue"):
        try:
            informacoes = scrape_dengue_info()
            
            # Exibir as informa√ß√µes no Streamlit
            for info in informacoes:
                st.write(info)
    
        except Exception as e:
            st.error(f"Erro ao carregar informa√ß√µes: {e}") 
                

    # CNN: Not√≠cias gerais
    if st.button("Carregar not√≠cias gerais"):
        try:
            cnn_news = scrape_cnn_news()
            if cnn_news:
                show_news_column(cnn_news, "Not√≠cias Gerais")
            else:
                st.write("Nenhuma not√≠cia encontrada.")
        except Exception as e:
            st.error(f"Erro ao carregar not√≠cias gerais: {e}")

    from user_global import ESTADO_USUARIO, MUNICIPIO_USUARIO

    if st.button("Carregar not√≠cias por estado e munic√≠pio"):

        try:
            state_news = scrape_g1_news(ESTADO_USUARIO)
            city_news = scrape_g1_news(ESTADO_USUARIO, MUNICIPIO_USUARIO) if MUNICIPIO_USUARIO else []
            
            if state_news:
                show_news_column(state_news, f"Not√≠cias no estado: {ESTADO_USUARIO}")
            else:
                st.write(f"Nenhuma not√≠cia encontrada para o estado {ESTADO_USUARIO}.")
            
            if city_news:
                show_news_column(city_news, f"Not√≠cias no munic√≠pio: {MUNICIPIO_USUARIO}")
            elif MUNICIPIO_USUARIO:
                st.write(f"Nenhuma not√≠cia encontrada para o munic√≠pio {MUNICIPIO_USUARIO}.")
        
        except Exception as e:
            st.error(f"Erro ao carregar not√≠cias do estado ou munic√≠pio: {e}")

